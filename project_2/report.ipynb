{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "#### UJ SN2019 Zadanie 2: Nocne Ptasie Wędrówki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "10s wav file recordings with assigned time intervals where bird voice was heard. <br>\n",
    "__Purpose__: Guess the probability of bird voice in given second in recording.\n",
    "\n",
    "Statistics about bird voices can be found in __first_approach/data_analysis.ipynb__.\n",
    "\n",
    "#### I have gathered following statistics:\n",
    "- count of intervals where bird was heard (for each recording)\n",
    "- are intervals correctly marked (stop time isn't after start) <br>\n",
    "    I wanted to remove all incorrectly marked intervals but there is no problem with it.\n",
    "- bird voice length\n",
    "    - Max length: 0.4543999999999997\n",
    "    - Min length: 0.0039999999999995595\n",
    "    - Median length: 0.020500000000000185\n",
    "    - Mean length: 0.058235670103092746<br>\n",
    "    Based on it, I have choosen length of interval for BirdDetector model (lower than max length and higher than mean -> twice a mean)\n",
    "- uniqueness of bird voice length\n",
    "- distribution of bird voice length with reference to median\n",
    "    - Higher than median: 30 (unique values: 13)\n",
    "    - Lower than median: 117 (unique values: 53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "For given recording, data was splitted into seconds. <br>\n",
    "For each second was checked: 'Was a bird voice in this second?'\n",
    "- no: <br>\n",
    "    interval was splitted into 0.1 s parts and for each was assigned 0 what means - bird does not exist in this time\n",
    "- yes: <br>\n",
    "    I have checked exact time where bird exists in given second and took interval [start_time - 1s, end_time + 1s] <br>\n",
    "    Then I checked how many intervals for positive samples should I create. Number is the same as count of samples where bird does not exist in recording. (number of second where there is no bird * 10). Multiplication by 10 because 1 second has ten 0.1s parts. <br>\n",
    "    For each interval I splitted it into 0.1s parts and check if bird voice was heard:\n",
    "    - If yes - assign 1\n",
    "    - If no - assign 0\n",
    "    \n",
    "__Final state of data__: spectrograms for 0.1s recording and corresponding label (0 or 1). <br>\n",
    "Spectrograms were normalized.\n",
    "\n",
    "Data was splitted into train (70%) and validation (30%).\n",
    "\n",
    "In train labels is:\n",
    "- negative samples (without bird voice): 2160\n",
    "- positive samples (with bird voice): 5113\n",
    "\n",
    "In validation labels is:\n",
    "- negative samples (without bird voice): 961\n",
    "- positive samples (with bird voice): 2156"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "Two models:\n",
    "1. convolutional neural network\n",
    "    - takes spectrogram for 0.1s as an input \n",
    "    - returns a probabilty of bird voice in 0.1s (0-1) <br>\n",
    "    __The highest validation roc auc: 0.685988128082064__\n",
    "2. MLP\n",
    "    - takes 10 next outputs from above model and join them, then give it as an input for MLP model\n",
    "    - returns probability of bird voice in given second (0-1)<br>\n",
    "    __The highest validation roc auc: 0.7633924884328613__\n",
    "    \n",
    "When there is no improvements in N following epochs, then training is stopped.\n",
    "    \n",
    "__Score on public kaggle leaderboard: 0.41438__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To reproduce my score:\n",
    "- unzip train and test data from https://www.kaggle.com/c/ujnn2019-2/data and place into first_approach\n",
    "- notebooks should be run in following order:\n",
    "    1. first_approach/data_analysis.ipynb\n",
    "       - for checking staticstics about recordings\n",
    "    2. first_approach/data_preparation.ipynb\n",
    "       - for preparing data for convolutional neural network\n",
    "    3. first_approach/model/balanced_data/convolutional_neural_network.ipynb\n",
    "       - for learning model on 0.1s samples and preparing data for classifier model\n",
    "    4. first_approach/model/balanced_data/classifier.ipynb\n",
    "       - for learning model on 1s samples and preparing final submission (based on joined 0.1s parts into 1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__In my opinion, this is the most promising approach__ (based on data preparation and choosing combination of two models - one predicts probability for small part of recording and second join them all and predict probability for 1 second). <br>\n",
    "\n",
    "First model is a core of this solution. If it has better validation roc auc score, then overall score could be much higher.<br>\n",
    "\n",
    "Final score looks like multiplication of the highest roc auc scores for those models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "For each second of recording spectrograms for 0.2s was created and then all was stacked one above the another. <br>\n",
    "For above representation was assigned:\n",
    "- 1 - with bird voice\n",
    "- 0 - without bird voice\n",
    "\n",
    "\n",
    "__Final state of data__: image consisting of 5 channels (in each channels is spectrogram for 0.2s) and corresponding label (0 or 1).\n",
    "\n",
    "__Important__: data is imbalanced in this case!\n",
    "\n",
    "\n",
    "#### Train data\n",
    "- Probability of class '0': 0.8717847249703206\n",
    "- Probability of class '1': 0.12821527502967947\n",
    "\n",
    "#### Validation data\n",
    "- Probability of class '0': 0.8707294552169899\n",
    "- Probability of class '1': 0.12927054478301014\n",
    "\n",
    "\n",
    "<cite>\"In the case of imbalanced data, majority classes dominate over minority classes, causing the machine learning classifiers to be more biased towards majority classes.\" </cite>\n",
    "\n",
    "I have created model to observe above. <br>\n",
    "Observations can be found in __second_approach/model/imbalanced_data/MLP.ipynb__:\n",
    "- Accuracy on validation dataset is really low(!). \n",
    "- Accuracy on training data is similar to percents of data representing \"bird does not exist\" values. \n",
    "- Model hasn't learned how to recognize rarely occuring value.\n",
    "\n",
    "#### Upsampling\n",
    "After it, I have decided to perform upsampling using imblearn.over_sampling.RandomOverSampler. Then I used sklearn.model_selection.StratifiedKFold for splitting data into train and validation with the same number of samples with labels 0 and 1.\n",
    "\n",
    "Before upsampling:\n",
    "- Number of samples for 'bird exists': 464\n",
    "- Number of samples for 'bird does not exists': 3146\n",
    "\n",
    "After upsampling and splitting into train and validation:\n",
    "- train\n",
    "    - Number of samples for 'bird exists': 2517\n",
    "    - Number of samples for 'bird does not exists': 2517\n",
    "- validation:\n",
    "    - Number of samples for 'bird exists': 629\n",
    "    - Number of samples for 'bird does not exists': 629"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "Convolutional neural network. <br>\n",
    "When there is no improvements in N following epochs, then training is stopped. <br>\n",
    "\n",
    "__The highest validation roc auc score: 0.5763912233565278__ <br>\n",
    "__Score on public kaggle leaderboard: 0.47123__  <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To reproduce my score:\n",
    "- unzip train and test data from https://www.kaggle.com/c/ujnn2019-2/data and place into second_approach\n",
    "- notebooks should be run in following order:\n",
    "    1. second_approach/imbalanced_data.ipynb\n",
    "       - for creating imbalanced train, validation data\n",
    "    2. second_approach/model/imbalanced_data/MLP.ipynb\n",
    "       - for checking ROC AUC score on imbalanced data\n",
    "    3. second_approach/balancing_data.ipynb\n",
    "       - for preparing balanced data\n",
    "    4. second_approach/model/balanced_data/convolutional_neural_network.ipynb\n",
    "       - for learning model on image consisting of 5 channels (in each channels is spectrogram for 0.2s) and preparing final submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Copy-paste helpers.ipynb from kaggle, replace model by convolutional neural network and align input for model.\n",
    "2. The same as above but with ReduceLROnPlateau learning rate scheduler.\n",
    "<br>\n",
    "\n",
    "Sounds boring? If I compare with above (in my opinion more creative ideas), for me - yes. <br>\n",
    "Time spent on first + second aproach (over a dozen of hours) was much higher than on third approach (some minutes). <br>\n",
    "Quite demotivating if I look at scores for all my approaches on public leaderboard on kaggle...\n",
    "\n",
    "Without ReduceLROnPlateau:\n",
    "- __The highest validation roc auc score: 0.691548716261__ <br>\n",
    "- __Score on public kaggle leaderboard: 0.81271__\n",
    "\n",
    "With ReduceLROnPlateau:\n",
    "- __The highest validation roc auc score: 0.7858403110047847__ <br>\n",
    "- __Score on public kaggle leaderboard: 0.72617__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To reproduce my score:\n",
    "- unzip train and test data from https://www.kaggle.com/c/ujnn2019-2/data and place into third_approach\n",
    "- run third_approach/helpers.ipynb or third_approach/helpers_ReduceLROnPlateau.ipynb (depending on what solution you want to reproduce)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
