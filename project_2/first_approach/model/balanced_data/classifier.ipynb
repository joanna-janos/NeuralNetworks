{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \"UJ SN2019 Zadanie 2: Nocne Ptasie Wędrówki\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x117e406b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "SEED = 1024\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load already prepared train and validation data for second model\n",
    "This model will classify whether in given second is bird voice or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "directory = 'data/'\n",
    "p = pathlib.Path(directory)\n",
    "if not p.is_dir():\n",
    "    raise ValueError('Directory: {directory} does not exist. Please, run firstly ConvNet.ipynb for creating data')\n",
    "    \n",
    "\n",
    "X_train_classifier = torch.load(directory + 'X_train_classifier.pt')\n",
    "y_train_classifier = torch.load(directory + 'y_train_classifier.pt')\n",
    "X_validation_classifier = torch.load(directory + 'X_validation_classifier.pt')\n",
    "y_validation_classifier = torch.load(directory + 'y_validation_classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "train_dataset_classifier = TensorDataset(X_train_classifier, y_train_classifier)\n",
    "validation_dataset_classifier = TensorDataset(X_validation_classifier, y_validation_classifier)\n",
    "    \n",
    "train_dataloader_classifier = DataLoader(train_dataset_classifier, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader_classifier = DataLoader(validation_dataset_classifier, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP model\n",
    "Input for this model is output from another model (convolutional neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier =  torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=10, out_features=300),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=300, out_features=150),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=150, out_features=1),\n",
    "    torch.nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 0\n",
      "Train accuracy: 0.7871019427198077\n",
      "Validation ROC AUC score: 0.7633924884328613\n",
      "\n",
      "EPOCH: 1\n",
      "Train accuracy: 0.8417784898858401\n",
      "Validation ROC AUC score: 0.7605395830734059\n",
      "\n",
      "EPOCH: 2\n",
      "Train accuracy: 0.8489885840176247\n",
      "Validation ROC AUC score: 0.759302474743836\n",
      "\n",
      "EPOCH: 3\n",
      "Train accuracy: 0.8527939114760665\n",
      "Validation ROC AUC score: 0.7594412979796826\n",
      "\n",
      "EPOCH: 4\n",
      "Train accuracy: 0.8459843781293811\n",
      "Validation ROC AUC score: 0.7616097520687297\n",
      "\n",
      "EPOCH: 5\n",
      "Train accuracy: 0.844181854596435\n",
      "Validation ROC AUC score: 0.7620314935447194\n",
      "\n",
      "EPOCH: 6\n",
      "Train accuracy: 0.8525936310835169\n",
      "Validation ROC AUC score: 0.757858888816646\n",
      "\n",
      "EPOCH: 7\n",
      "Train accuracy: 0.8563989585419587\n",
      "Validation ROC AUC score: 0.7610131636058193\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "epoch = 30\n",
    "optimizer_classifier: torch.optim.Optimizer = optim.Adam(classifier.parameters())\n",
    "criterion_classifier = torch.nn.BCELoss()\n",
    "best_validation_score_classifier = 0\n",
    "epochs_without_improvement_classifier = 0\n",
    "MAX_POSSIBLE_EPOCHS_WITHOUT_IMPROVEMENT_CLASSIFIER = 7\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    preds_second_model_train = []\n",
    "    y_labels_second_model_train = []\n",
    "    print(f\"\\nEPOCH: {e}\")\n",
    "    loss_train_classifier : int = 0\n",
    "    correct_train_classifier: int = 0\n",
    "    for i, (x, y) in enumerate(train_dataloader_classifier):\n",
    "        correct_in_batch_classifier = 0\n",
    "        optimizer_classifier.zero_grad()\n",
    "        output_classifier: torch.Tensor = classifier(x)\n",
    "        loss_classifier: torch.Tensor = criterion_classifier(output_classifier.flatten(), y)\n",
    "        loss_classifier.backward()\n",
    "        optimizer_classifier.step()\n",
    "        loss_train_classifier += loss_classifier.item()\n",
    "        for predicted, correct in zip(output_classifier.flatten(), y): \n",
    "            if predicted >= 0.5 and correct==1:\n",
    "                correct_in_batch_classifier += 1\n",
    "            if predicted < 0.5 and correct==0:\n",
    "                correct_in_batch_classifier += 1\n",
    "        correct_train_classifier += correct_in_batch_classifier\n",
    "    print(f\"Train accuracy: {correct_train_classifier / len(y_train_classifier)}\")\n",
    "    \n",
    "    preds_second_model_validation = []\n",
    "    y_labels_second_model_validation = []\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(validation_dataloader_classifier):\n",
    "            output_classifier: torch.Tensor = classifier(x)\n",
    "            preds_second_model_validation.append(output_classifier.flatten())\n",
    "            y_labels_second_model_validation.append(y)\n",
    "        preds_second_model_validation = torch.cat(preds_second_model_validation)\n",
    "        y_labels_second_model_validation = torch.cat(y_labels_second_model_validation)\n",
    "        validation_score_classifier = roc_auc_score(y_labels_second_model_validation.numpy(), preds_second_model_validation.numpy())\n",
    "        print(f\"Validation ROC AUC score: {validation_score_classifier}\")\n",
    "        if validation_score_classifier > best_validation_score_classifier:\n",
    "            best_validation_score_classifier = validation_score_classifier\n",
    "            torch.save(classifier.state_dict(), '../../saved_model/model_classifier.pt')\n",
    "            epochs_without_improvement_classifier = 0\n",
    "        else:\n",
    "            epochs_without_improvement_classifier +=1\n",
    "        if epochs_without_improvement_classifier == MAX_POSSIBLE_EPOCHS_WITHOUT_IMPROVEMENT_CLASSIFIER:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare first model (convolutional neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdDetector(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BirdDetector, self).__init__()\n",
    "        self.pool = torch.nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=128, kernel_size=5, padding=2)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=128, out_channels=96, kernel_size=5, padding=2)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(96)\n",
    "        \n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=96, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(448, 100)\n",
    "        self.fc2 = torch.nn.Linear(100, 1)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.pool(self.bn1(torch.relu(self.conv1(x))))\n",
    "        out = self.pool(self.bn2(torch.relu(self.conv2(out))))\n",
    "        out = self.pool(self.bn3(torch.relu(self.conv3(out))))\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return self.sigmoid(out)\n",
    "    \n",
    "model = BirdDetector()\n",
    "model.load_state_dict(torch.load('../../saved_model/model.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load already prepared test data and use it to predict whether in given recording and second is bird voice or not\n",
    "Get output from first model (convolutional neural network) and us it as input for second model (classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def load_data(directory, dataset_name):\n",
    "    p = pathlib.Path(directory)\n",
    "    if not p.is_dir():\n",
    "        raise ValueError('Directory: {directory} does not exist. Please, run firstly convolutional_neural_network.ipynb for creating data')\n",
    "    return np.load(pathlib.Path(directory + dataset_name + '.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_directory = '../../data/'\n",
    "\n",
    "test_X = load_data(test_data_directory, 'X_test')\n",
    "test_X = test_X.reshape(-1, test_X.shape[2], test_X.shape[3])\n",
    "X_test = torch.from_numpy(test_X).float()\n",
    "test_dataset = TensorDataset(X_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions_test = []\n",
    "    for x in test_dataloader:\n",
    "        output: torch.Tensor = model(x[0].view(-1, 1, x[0].shape[1], x[0].shape[2]))\n",
    "        predictions_test.append(output.view(-1))\n",
    "    predictions_test = torch.cat(predictions_test)\n",
    "    test_input_for_second_model = []\n",
    "    for i in range(0, len(predictions_test), 10):\n",
    "        test_input_for_second_model.append(predictions_test[i : i+10])\n",
    "    X_test_classifier: torch.Tensor = torch.stack(test_input_for_second_model)\n",
    "    test_dataset_classifier = TensorDataset(X_test_classifier)\n",
    "    test_dataloader_classifier = DataLoader(test_dataset_classifier, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    test_outputs = []\n",
    "    for x in test_dataloader_classifier:\n",
    "        output_classifier: torch.Tensor = classifier(x[0])\n",
    "        test_outputs.append(output_classifier.flatten())\n",
    "    test_outputs = torch.cat(test_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions for test\n",
    "Only for recordings and seconds from sampleSubmission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_indices_from_sample_submission():\n",
    "    sample_submission_csv = pd.read_csv('../../submission/sampleSubmission.csv')\n",
    "    return sample_submission_csv['sample_id'].tolist()\n",
    "\n",
    "def create_dataframe_with_predictions(predictions):\n",
    "    indices_from_sample_submission = get_indices_from_sample_submission()\n",
    "    submission_df = pd.DataFrame(columns=['sample_id', 'prediction'])\n",
    "    for i, element in enumerate(predictions):\n",
    "        submission_df.loc[i] = [str(int(i/10)+1) + '/' +str(i%10)] + [element]\n",
    "    return submission_df[submission_df['sample_id'].isin(indices_from_sample_submission)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission_df = create_dataframe_with_predictions(test_outputs.numpy())\n",
    "my_submission_df.to_csv('../../submission/mySubmission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
