{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \"UJ SN2019 Zadanie 2: Nocne Ptasie Wędrówki\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP for imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "def load_data(directory, dataset_name):\n",
    "    p = pathlib.Path(directory)\n",
    "    if not p.is_dir():\n",
    "        raise ValueError('Directory: {directory} does not exist. Please, run firstly imbalanced_data.ipynb for creating data')\n",
    "    return np.load(pathlib.Path(directory + dataset_name + '.npy'))\n",
    "\n",
    "data_dir = '../../data/imbalanced/splitted/'\n",
    "X_train = load_data(data_dir, 'X_train')\n",
    "y_train = load_data(data_dir, 'y_train')\n",
    "X_validation = load_data(data_dir, 'X_validation')\n",
    "y_validation = load_data(data_dir, 'y_validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from typing import Sequence\n",
    "\n",
    "def get_train_and_validation_datasets(train_X, train_y, validation_X, validation_y) -> Sequence[torch.utils.data.TensorDataset]:\n",
    "    X_train: torch.Tensor = torch.from_numpy(train_X).float()\n",
    "    X_validation: torch.Tensor = torch.from_numpy(validation_X).float()\n",
    "        \n",
    "    y_train: torch.Tensor = torch.from_numpy(train_y.flatten()).long()\n",
    "    y_validation: torch.Tensor = torch.from_numpy(validation_y.flatten()).long()\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    validation_dataset = TensorDataset(X_validation, y_validation)\n",
    "    \n",
    "    return train_dataset, validation_dataset\n",
    "\n",
    "\n",
    "train_dataset, validation_dataset = get_train_and_validation_datasets(\n",
    "    X_train, y_train, X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How MLP model works on imbalanced data for this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(5400, 2500)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(2500, 500)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.linear3 = torch.nn.Linear(500, 2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.flatten(x, start_dim = 1)\n",
    "        out = self.relu1(self.linear1(out))\n",
    "        out = self.relu2(self.linear2(out))\n",
    "        out = self.relu3(self.linear3(out))\n",
    "        return out\n",
    "    \n",
    "model = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "Train accuracy: 0.8717847249703206\n",
      "Loss: 0.006891662989815658\n",
      "Validation accuracy: 0.02585410895660203\n",
      "\n",
      "EPOCH: 1\n",
      "Train accuracy: 0.8717847249703206\n",
      "Loss: 0.005936732164097247\n",
      "Validation accuracy: 0.02677746999076639\n",
      "\n",
      "EPOCH: 2\n",
      "Train accuracy: 0.8717847249703206\n",
      "Loss: 0.006059842957401162\n",
      "Validation accuracy: 0.024007386888273315\n",
      "\n",
      "EPOCH: 3\n",
      "Train accuracy: 0.8717847249703206\n",
      "Loss: 0.005919334807790311\n",
      "Validation accuracy: 0.02585410895660203\n",
      "\n",
      "EPOCH: 4\n",
      "Train accuracy: 0.8717847249703206\n",
      "Loss: 0.005926586159803106\n",
      "Validation accuracy: 0.024930747922437674\n",
      "\n",
      "EPOCH: 5\n",
      "Train accuracy: 0.8717847249703206\n",
      "Loss: 0.005874053251144204\n",
      "Validation accuracy: 0.027700831024930747\n",
      "\n",
      "EPOCH: 6\n",
      "Train accuracy: 0.8721804511278195\n",
      "Loss: 0.00592719816883232\n",
      "Validation accuracy: 0.02585410895660203\n",
      "\n",
      "EPOCH: 7\n",
      "Train accuracy: 0.8721804511278195\n",
      "Loss: 0.005921236619347398\n",
      "Validation accuracy: 0.024007386888273315\n",
      "\n",
      "EPOCH: 8\n",
      "Train accuracy: 0.8725761772853186\n",
      "Loss: 0.005887972232990695\n",
      "Validation accuracy: 0.024007386888273315\n",
      "\n",
      "EPOCH: 9\n",
      "Train accuracy: 0.8721804511278195\n",
      "Loss: 0.005846458476524746\n",
      "Validation accuracy: 0.027700831024930747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer: torch.optim.Optimizer = optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "epoch: int = 10\n",
    "    \n",
    "for e in range(epoch):\n",
    "    print(f\"EPOCH: {e}\")\n",
    "    \n",
    "    correct_train: int = 0 \n",
    "    loss_train : int = 0\n",
    "    for i, (x, y) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output: torch.Tensor = model(x)\n",
    "        loss: torch.Tensor = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct_train += float(sum(output.argmax(dim=1) == y))\n",
    "        loss_train += loss.item()\n",
    "\n",
    "    print(f\"Train accuracy: {correct_train / len(train_dataset)}\")\n",
    "    print(f\"Loss: {loss_train / len(train_dataset)}\")\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        correct_validation = float(sum(output.argmax(dim=1) == y))\n",
    "        print(f\"Validation accuracy: {correct_validation / len(validation_dataset)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result:\n",
    "As expected, accuracy on validation dataset is really low(!). <br>\n",
    "Accuracy on training dataset is similar to percents of data representing \"bird does not exist\" values. <br>\n",
    "Model hasn't learned how to recognize rarely occuring value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
