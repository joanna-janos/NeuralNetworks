{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \"UJ SN2019 Zadanie 2: Nocne Ptasie Wędrówki\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet for balanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "SEED = 1024\n",
    "np.random.seed(SEED)\n",
    "import pathlib\n",
    "\n",
    "def load_data(directory, dataset_name):\n",
    "    p = pathlib.Path(directory)\n",
    "    if not p.is_dir():\n",
    "        raise ValueError('Directory: {directory} does not exist. Please, run firstly imbalanced_data.ipynb for creating data')\n",
    "    return np.load(pathlib.Path(directory + dataset_name + '.npy'))\n",
    "\n",
    "\n",
    "def load_train_and_validation_data(data_dir):\n",
    "    X_train = load_data(data_dir, 'X_train')\n",
    "    y_train = load_data(data_dir, 'y_train')\n",
    "    X_validation = load_data(data_dir, 'X_validation')\n",
    "    y_validation = load_data(data_dir, 'y_validation')\n",
    "    return X_train, y_train, X_validation, y_validation\n",
    "\n",
    "\n",
    "data_directory = '../../data/balanced/splitted/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from typing import Sequence\n",
    "torch.manual_seed(SEED) \n",
    "\n",
    "BATCH_SIZE = 64\n",
    "    \n",
    "def get_train_and_validation_dataloaders(train_X, train_y, validation_X, validation_y, batch_size=64) -> Sequence[torch.utils.data.TensorDataset]:\n",
    "    X_train: torch.Tensor = torch.from_numpy(train_X).float()\n",
    "    X_validation: torch.Tensor = torch.from_numpy(validation_X).float()\n",
    "        \n",
    "    y_train: torch.Tensor = torch.from_numpy(train_y.flatten()).float()\n",
    "    y_validation: torch.Tensor = torch.from_numpy(validation_y.flatten()).float()\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    validation_dataset = TensorDataset(X_validation, y_validation)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n",
    "  \n",
    "    return train_dataloader, validation_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, validation_X, validation_y = load_train_and_validation_data(data_directory)\n",
    "train_dataloader, validation_dataloader = get_train_and_validation_dataloaders(train_X, train_y, validation_X, validation_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdDetector(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BirdDetector, self).__init__()\n",
    "        self.pool = torch.nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=5, out_channels=5, kernel_size=3, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(5)\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=5, out_channels=3, kernel_size=3, padding=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(3)\n",
    "        \n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(3)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(42, 20)\n",
    "        self.fc2 = torch.nn.Linear(20, 1)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.pool(self.bn1(torch.relu(self.conv1(x))))\n",
    "        out = self.pool(self.bn2(torch.relu(self.conv2(out))))\n",
    "        out = self.pool(self.bn3(torch.relu(self.conv3(out))))\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return self.sigmoid(out)\n",
    "    \n",
    "model = BirdDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_models_directory = '../../saved_model/'\n",
    "\n",
    "p = pathlib.Path(saved_models_directory)\n",
    "if not p.is_dir():\n",
    "    print(f'Creating directory: {saved_models_directory} as it does not exist')\n",
    "    p.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "Train accuracy: 0.533373063170441\n",
      "Loss: 0.010636616402028523\n",
      "Validation ROC_AUC score: 0.46584403537550456\n",
      "\n",
      "EPOCH: 1\n",
      "Train accuracy: 0.5484704012713548\n",
      "Loss: 0.010373017003624318\n",
      "Validation ROC_AUC score: 0.5150287760874126\n",
      "\n",
      "EPOCH: 2\n",
      "Train accuracy: 0.5580055621771951\n",
      "Loss: 0.010151262931232656\n",
      "Validation ROC_AUC score: 0.4649859342181422\n",
      "\n",
      "EPOCH: 3\n",
      "Train accuracy: 0.5756853396901073\n",
      "Loss: 0.010251434492506014\n",
      "Validation ROC_AUC score: 0.5273568715072503\n",
      "\n",
      "EPOCH: 4\n",
      "Train accuracy: 0.5923718712753278\n",
      "Loss: 0.010172400000458158\n",
      "Validation ROC_AUC score: 0.5232496126538958\n",
      "\n",
      "EPOCH: 5\n",
      "Train accuracy: 0.5993245927691696\n",
      "Loss: 0.009889654912880408\n",
      "Validation ROC_AUC score: 0.32865021572587266\n",
      "\n",
      "EPOCH: 6\n",
      "Train accuracy: 0.6128327373857767\n",
      "Loss: 0.009833418238385594\n",
      "Validation ROC_AUC score: 0.5496725566864911\n",
      "\n",
      "EPOCH: 7\n",
      "Train accuracy: 0.6380611839491458\n",
      "Loss: 0.009563484360502028\n",
      "Validation ROC_AUC score: 0.5763912233565278\n",
      "\n",
      "EPOCH: 8\n",
      "Train accuracy: 0.6537544696066746\n",
      "Loss: 0.009402899110795584\n",
      "Validation ROC_AUC score: 0.4604515204440389\n",
      "\n",
      "EPOCH: 9\n",
      "Train accuracy: 0.6493841875248312\n",
      "Loss: 0.00940366506718623\n",
      "Validation ROC_AUC score: 0.4897571283057115\n",
      "\n",
      "EPOCH: 10\n",
      "Train accuracy: 0.6618990862137465\n",
      "Loss: 0.009214531821204311\n",
      "Validation ROC_AUC score: 0.5405531782600893\n",
      "\n",
      "EPOCH: 11\n",
      "Train accuracy: 0.6660707191100517\n",
      "Loss: 0.009159616252757463\n",
      "Validation ROC_AUC score: 0.529809852871669\n",
      "\n",
      "EPOCH: 12\n",
      "Train accuracy: 0.6783869686134287\n",
      "Loss: 0.009115454876617066\n",
      "Validation ROC_AUC score: 0.5182968903627277\n",
      "\n",
      "EPOCH: 13\n",
      "Train accuracy: 0.6841477949940405\n",
      "Loss: 0.00879884896341846\n",
      "Validation ROC_AUC score: 0.5336062238241234\n",
      "\n",
      "EPOCH: 14\n",
      "Train accuracy: 0.6948748510131109\n",
      "Loss: 0.008694363962955119\n",
      "Validation ROC_AUC score: 0.48435450319860684\n",
      "\n",
      "EPOCH: 15\n",
      "Train accuracy: 0.6883194278903456\n",
      "Loss: 0.00879392121394191\n",
      "Validation ROC_AUC score: 0.5336226528595368\n",
      "\n",
      "EPOCH: 16\n",
      "Train accuracy: 0.6980532379817243\n",
      "Loss: 0.008539259848160832\n",
      "Validation ROC_AUC score: 0.4559196342138454\n",
      "\n",
      "EPOCH: 17\n",
      "Train accuracy: 0.6988478347238777\n",
      "Loss: 0.008559645418141349\n",
      "Validation ROC_AUC score: 0.47328133332996336\n",
      "\n",
      "EPOCH: 18\n",
      "Train accuracy: 0.711362733412793\n",
      "Loss: 0.008439041197560447\n",
      "Validation ROC_AUC score: 0.5047227157953802\n",
      "\n",
      "EPOCH: 19\n",
      "Train accuracy: 0.7054032578466428\n",
      "Loss: 0.008474058038334929\n",
      "Validation ROC_AUC score: 0.48065417891472323\n",
      "\n",
      "EPOCH: 20\n",
      "Train accuracy: 0.7099721891140246\n",
      "Loss: 0.008412910439592058\n",
      "Validation ROC_AUC score: 0.46006101490998147\n",
      "\n",
      "EPOCH: 21\n",
      "Train accuracy: 0.7177195073500199\n",
      "Loss: 0.00833484044991934\n",
      "Validation ROC_AUC score: 0.529114778296486\n",
      "\n",
      "EPOCH: 22\n",
      "Train accuracy: 0.7111640842272546\n",
      "Loss: 0.008381648768401117\n",
      "Validation ROC_AUC score: 0.48571811313792057\n",
      "\n",
      "EPOCH: 23\n",
      "Train accuracy: 0.7193087008343266\n",
      "Loss: 0.008101361804080474\n",
      "Validation ROC_AUC score: 0.49191312326073383\n",
      "\n",
      "EPOCH: 24\n",
      "Train accuracy: 0.7266587206992451\n",
      "Loss: 0.008049982576603259\n",
      "Validation ROC_AUC score: 0.5186166246673121\n",
      "\n",
      "EPOCH: 25\n",
      "Train accuracy: 0.7135478744537147\n",
      "Loss: 0.008395476400686438\n",
      "Validation ROC_AUC score: 0.49085534613450066\n",
      "\n",
      "EPOCH: 26\n",
      "Train accuracy: 0.7286452125546286\n",
      "Loss: 0.007971500208986909\n",
      "Validation ROC_AUC score: 0.5152284520562833\n",
      "\n",
      "EPOCH: 27\n",
      "Train accuracy: 0.723083035359555\n",
      "Loss: 0.00813559494560372\n",
      "Validation ROC_AUC score: 0.494040051460794\n",
      "\n",
      "EPOCH: 28\n",
      "Train accuracy: 0.725466825586015\n",
      "Loss: 0.008190226823648006\n",
      "Validation ROC_AUC score: 0.5159513296144738\n",
      "\n",
      "EPOCH: 29\n",
      "Train accuracy: 0.72010329757648\n",
      "Loss: 0.008011575150357194\n",
      "Validation ROC_AUC score: 0.4929001291574937\n",
      "\n",
      "EPOCH: 30\n",
      "Train accuracy: 0.7369884783472388\n",
      "Loss: 0.007888505915398157\n",
      "Validation ROC_AUC score: 0.5164909602392067\n",
      "\n",
      "EPOCH: 31\n",
      "Train accuracy: 0.7302344060389352\n",
      "Loss: 0.007939560472799475\n",
      "Validation ROC_AUC score: 0.5696123505905607\n",
      "\n",
      "EPOCH: 32\n",
      "Train accuracy: 0.733611442193087\n",
      "Loss: 0.007984433493350866\n",
      "Validation ROC_AUC score: 0.4567663614236138\n",
      "\n",
      "EPOCH: 33\n",
      "Train accuracy: 0.7268573698847834\n",
      "Loss: 0.007998074941044058\n",
      "Validation ROC_AUC score: 0.48940074461443583\n",
      "\n",
      "EPOCH: 34\n",
      "Train accuracy: 0.7395709177592372\n",
      "Loss: 0.007812176229795578\n",
      "Validation ROC_AUC score: 0.509011957810237\n",
      "\n",
      "EPOCH: 35\n",
      "Train accuracy: 0.7359952324195471\n",
      "Loss: 0.0078007926069937105\n",
      "Validation ROC_AUC score: 0.4743656496672488\n",
      "\n",
      "EPOCH: 36\n",
      "Train accuracy: 0.7258641239570918\n",
      "Loss: 0.00809711953169967\n",
      "Validation ROC_AUC score: 0.4549288370012208\n",
      "\n",
      "EPOCH: 37\n",
      "Train accuracy: 0.7316249503377036\n",
      "Loss: 0.007983087108018714\n",
      "Validation ROC_AUC score: 0.5178785818456632\n",
      "\n",
      "EPOCH: 38\n",
      "Train accuracy: 0.7359952324195471\n",
      "Loss: 0.00783042136667075\n",
      "Validation ROC_AUC score: 0.5060307197686791\n",
      "\n",
      "EPOCH: 39\n",
      "Train accuracy: 0.7338100913786253\n",
      "Loss: 0.008017217936523387\n",
      "Validation ROC_AUC score: 0.48883204723474055\n",
      "\n",
      "EPOCH: 40\n",
      "Train accuracy: 0.744139849026619\n",
      "Loss: 0.007760737670003113\n",
      "Validation ROC_AUC score: 0.46807080156000014\n",
      "\n",
      "EPOCH: 41\n",
      "Train accuracy: 0.7417560588001589\n",
      "Loss: 0.007700567290240164\n",
      "Validation ROC_AUC score: 0.4475054405382657\n",
      "\n",
      "EPOCH: 42\n",
      "Train accuracy: 0.7371871275327772\n",
      "Loss: 0.007684534901799689\n",
      "Validation ROC_AUC score: 0.4864018137655096\n",
      "\n",
      "EPOCH: 43\n",
      "Train accuracy: 0.7421533571712357\n",
      "Loss: 0.007665733733156346\n",
      "Validation ROC_AUC score: 0.4916009715878789\n",
      "\n",
      "EPOCH: 44\n",
      "Train accuracy: 0.7385776718315455\n",
      "Loss: 0.007825849557803839\n",
      "Validation ROC_AUC score: 0.5431338005919508\n",
      "\n",
      "EPOCH: 45\n",
      "Train accuracy: 0.7369884783472388\n",
      "Loss: 0.007638093464470213\n",
      "Validation ROC_AUC score: 0.4794131548550327\n",
      "\n",
      "EPOCH: 46\n",
      "Train accuracy: 0.7274533174413985\n",
      "Loss: 0.007828696236091328\n",
      "Validation ROC_AUC score: 0.5580993880816194\n",
      "\n",
      "EPOCH: 47\n",
      "Train accuracy: 0.7387763210170838\n",
      "Loss: 0.0077063231760422105\n",
      "Validation ROC_AUC score: 0.48062637593171587\n",
      "\n",
      "EPOCH: 48\n",
      "Train accuracy: 0.7365911799761621\n",
      "Loss: 0.00790034956197015\n",
      "Validation ROC_AUC score: 0.5218000662216504\n",
      "\n",
      "EPOCH: 49\n",
      "Train accuracy: 0.7407628128724673\n",
      "Loss: 0.007719109307739249\n",
      "Validation ROC_AUC score: 0.5028814000571225\n",
      "\n",
      "EPOCH: 50\n",
      "Train accuracy: 0.755264203416766\n",
      "Loss: 0.007626580183213317\n",
      "Validation ROC_AUC score: 0.48984685611450784\n",
      "\n",
      "EPOCH: 51\n",
      "Train accuracy: 0.7421533571712357\n",
      "Loss: 0.007787179102677886\n",
      "Validation ROC_AUC score: 0.45502741121370127\n",
      "\n",
      "EPOCH: 52\n",
      "Train accuracy: 0.7495033770361541\n",
      "Loss: 0.007574873822854065\n",
      "Validation ROC_AUC score: 0.4930543093359889\n",
      "\n",
      "EPOCH: 53\n",
      "Train accuracy: 0.7514898688915376\n",
      "Loss: 0.0075612980361774796\n",
      "Validation ROC_AUC score: 0.48979125014849323\n",
      "\n",
      "EPOCH: 54\n",
      "Train accuracy: 0.7451330949543107\n",
      "Loss: 0.007870915156770993\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "optimizer: torch.optim.Optimizer = optim.Adam(model.parameters())\n",
    "criterion = torch.nn.BCELoss()\n",
    "epoch: int = 200\n",
    "\n",
    "best_validation_roc_auc = 0\n",
    "epochs_without_improvement = 0\n",
    "MAX_POSSIBLE_EPOCHS_WITHOUT_IMPROVEMENT = 50\n",
    "\n",
    "for e in range(epoch):\n",
    "    print(f\"EPOCH: {e}\")\n",
    "    \n",
    "    correct_train: int = 0 \n",
    "    loss_train : int = 0\n",
    "    for i, (x, y) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output: torch.Tensor = model(x)\n",
    "        loss: torch.Tensor = criterion(output.flatten(), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct_in_batch = 0\n",
    "        out_copy = output.clone().detach()\n",
    "        for out, label in zip(output,y):\n",
    "            if out.item() > 0.5 and label==1:\n",
    "                correct_in_batch += 1\n",
    "            if out.item() < 0.5 and label==0:\n",
    "                correct_in_batch += 1\n",
    "        correct_train += correct_in_batch\n",
    "        loss_train += loss.item()\n",
    "\n",
    "    print(f\"Train accuracy: {correct_train / len(train_X)}\")\n",
    "    print(f\"Loss: {loss_train / len(train_X)}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds = []\n",
    "        for i, (x, y) in enumerate(validation_dataloader):\n",
    "            output: torch.Tensor = model(x)\n",
    "            preds += output.tolist()\n",
    "        score = roc_auc_score(validation_y, preds)\n",
    "        \n",
    "        if score > best_validation_roc_auc:\n",
    "            best_validation_roc_auc = score\n",
    "            torch.save(model.state_dict(), '../../saved_model/model.pt')\n",
    "            epochs_without_improvements = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            \n",
    "        if epochs_without_improvement == MAX_POSSIBLE_EPOCHS_WITHOUT_IMPROVEMENT:\n",
    "            break\n",
    "            \n",
    "        print(f\"Validation ROC_AUC score: {score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest validation roc auc: 0.5763912233565278\n"
     ]
    }
   ],
   "source": [
    "print(f\"The highest validation roc auc: {best_validation_roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_directory = '../../data/imbalanced/'\n",
    "\n",
    "test_X = load_data(test_data_directory, 'X_test')\n",
    "X_test = torch.from_numpy(test_X).float()\n",
    "test_dataset = TensorDataset(X_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = BirdDetector()\n",
    "model.load_state_dict(torch.load('../../saved_model/model.pt'))\n",
    "\n",
    "test_predictions = []\n",
    "with torch.no_grad():\n",
    "    for x in test_dataloader:\n",
    "        out = model(x[0])\n",
    "        test_predictions.append(out.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_indices_from_sample_submission():\n",
    "    sample_submission_csv = pd.read_csv('../../submission/sampleSubmission.csv')\n",
    "    return sample_submission_csv['sample_id'].tolist()\n",
    "\n",
    "def create_dataframe_with_predictions(predictions):\n",
    "    indices_from_sample_submission = get_indices_from_sample_submission()\n",
    "    submission_df = pd.DataFrame(columns=['sample_id', 'prediction'])\n",
    "    for i, element in enumerate(predictions):\n",
    "        submission_df.loc[i] = [str(int(i/10)+1) + '/' +str(i%10)] + [element]\n",
    "    return submission_df[submission_df['sample_id'].isin(indices_from_sample_submission)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission_df = create_dataframe_with_predictions(torch.cat(test_predictions).numpy())\n",
    "my_submission_df.to_csv('../../submission/mySubmission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
